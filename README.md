# Self-Instruction for LLM

This repo is an experimental code that use self-generated instruction data from Llama to fine-tune a LoRA Patch over it, in order to derive an instruction-aligned chat model.